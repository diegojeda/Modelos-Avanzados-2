{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Sistemas de Recomendación basados en contenido\n",
    "\n",
    "## Actividad 11\n",
    "\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "En este cuadernos estudiaremos los sistemas de recomendacion basados en contenido. Seguiremos trabajando con  la base de datos de películas de IMDB (https://www.imdb.com/) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Los recomendadores basados en contenido se construyen a partir de la identificación de ítems que el usuario prefiere, y la búsqueda de ítems similares en función de determinados atributos, como por ejemplo el género, la sinopsis o el reparto (actores, etc). De esta manera, si el usuario tiene unas preferencias específicas sobre un ítem específico, también podría tener preferencia por un ítem *similar*.\n",
    "\n",
    "Primero carguemos los datos con los que vamos a trabajar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la biblioteca Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos de peliculas de la base de datos IMDB\n",
    "metadata = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "\n",
    "print(metadata.shape)\n",
    "      \n",
    "list(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Así se ven los datos\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 .Recomendación de peliculas mas populares por genero\n",
    "\n",
    "Ahora recordemos la recomendación de películas por género de acuerdo con su popularidad, donde calculamos el voto promedio ponderado $\\mu_i$, de la $i$-ésima película como:\n",
    "\n",
    "$$\n",
    "\\mu_i  = \\left( \\frac{v_i}{v_{max}} \\right) R_i \n",
    "$$\n",
    "\n",
    "donde $v_i$ es el número de votos para la $i$-ésima película, $v_{max}$ es el máximo número de votos que recibe la película más popular, y $R$ es el rating promedio de la pelicula.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "# trabajamos la informacion por generos\n",
    "metadata['genres'] = metadata['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "# añadimos la variable del año\n",
    "metadata['year'] = pd.to_datetime(metadata['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero nos quedamos con todos los generos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generos = metadata.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "generos.name = 'genre'\n",
    "gen_md = metadata.drop('genres', axis=1).join(generos)\n",
    "\n",
    "gen_md.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos una funcion para un género particular y que tome en cuenta peliculas con un número vmin de votos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_gen(genero, vmin):\n",
    "    df = gen_md[gen_md['genre'] == genero]\n",
    "    v = df[df['vote_count'].notnull()]['vote_count'].astype('int')\n",
    "    R = df[df['vote_average'].notnull()]['vote_average'].astype('int')\n",
    "    m = df['vote_average'].max()\n",
    "    \n",
    "    pelisG = df[(df['vote_count'] >= vmin) & (df['vote_count'].notnull()) & (df['vote_average'].notnull())][['title', 'year', 'vote_count', 'vote_average', 'popularity', 'overview', 'homepage']]\n",
    "    pelisG['vote_count'] = pelisG['vote_count'].astype('int')\n",
    "    pelisG['vote_average'] = pelisG['vote_average'].astype('int')\n",
    "    \n",
    "    pelisG['wr'] = v/m * R\n",
    "    pelisG = pelisG.sort_values('wr', ascending=False).head(250)\n",
    "    \n",
    "    return pelisG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el Top-15 de recomendaciones en Ciencia Ficción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "scifi = rec_gen('Science Fiction', 1000)\n",
    "scifi.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception e Interstellar aparecen en las dos primeras posiciones. Personalmente me gusta más Interstellar (si quieres ver un agujero negro, esta película es lo mejor que podrás conseguir), pero reconozco que Inception tiene mucho nivel. Podemos seguir refinando este tipo de recomendaciones prestando atención a los distintos atributos que tenemos disponibles sobre las películas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sistemas de recomendación basados en contenido\n",
    "\n",
    "Este tipo de sistemas basados en contenido utiliza información específica sobre el ítem o producto de recomendación. Por ejemplo, si no contamos con información del rating de las peliculas pero sabemos que un usuario vió o que le gustó cierta película, podríamos utilizar la descripción o resumen de la película para construir nuevas recomendaciones a partir de peliculas con contenidos *similares*.\n",
    "\n",
    "A continuación vamos a construir un sistema que recomiende películas en función de sus descripciones o \"su trama\". Entonces necesitamos calcular funciones de similitud de acuerdo con la descripción linguistica de cada película.\n",
    "\n",
    "En nuestros datos, la descripción de cada película la encontramos bajo el atributo \"overview\". Veamos a continuación las tramas de las primeras 5 peliculas recomendadas de Ciencia Ficcion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "scifi[['title', 'overview']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Estimación de similitudes y procesamiento de lenguage natural\n",
    "\n",
    "En primera instancia podemos evaluar las similitudes entre las películas a partir de la descripción linguística de su contenido. Pero, **¿cómo calculamos estas similitudes, o más aun, cómo procesamos los caracteres linguisticos, las palabras y las frases para calcular dichas similitudes?**\n",
    "\n",
    "A continuación vamos a ver una primera aproximación al análisis de texto a nivel de *términos* o *palabras*. Para ello, vamos a computar el ínidice TF-IDF (del inglés \"Term Frequency-Inverse Document Frequency\"), el cual se puede entender como una ponderación de la relevancia de los términos encontrados en cada resumen.  \n",
    "\n",
    "### 3.1.1 Indice TF-IDF\n",
    "El índice TF-IDF mide la relevancia de un término linguístico ($t$) por cada resumen o documento que estemos analizando ($d$), tomando la frecuencia del término en cada resumen $tf(t,d)$, y multiplicandola por la frecuencia inversa de la ocurrencia del término en la muestra de resumenes $idf(t)$. De esta manera se extrae la importancia/significancia de los términos/palabras como información numérica para la estimación de la similitud entre películas.\n",
    "\n",
    "Consideremos un conjunto de resumenes ($D$). En este conjunto es de esperar que los artículos linguísticos sean muy comunes (en ingles \"a\", \"the\",...), los cuales no ofrecen en verdad información relevante acerca del contenido de una película. Entonces, si fueramos a introducir el conteo de las palabras directamente a nuestro cálculo de las similitudes (o a un clasificador), esos términos más frecuentes añadirían ruido sobre otros términos menos frecuentes pero posiblemente más interesantes (en verdad relevantes para entender el contenido de las películas). \n",
    "\n",
    "De esta manera, la frecuencia de un término $t$ en un resumen $d$ está dada por $tf(t,d)$, y el índice $tf-idf(t,d)$ está dado por \n",
    "\n",
    "$$tf-idf(t,d)=tf(t,d)\\times idf(t)  $$\n",
    "\n",
    "donde $$ idf(t)=\\log \\frac{1+n}{1+df(t)}+1 $$\n",
    "\n",
    "siendo $n$ el número total de resumenes en $D$ y $df(t)$ es el número de resumenes en $D$ que contienen el término $t$.\n",
    " \n",
    "El resultado de los vectores $tf-idf(d)$, de todos los términos en cada documento, son normalizados por la norma Euclideana $L2$, tal que \n",
    "\n",
    "$$ tf-idf(t,d)_{norm} = \\frac{tf-idf(t,d)}{\\sqrt{tf-idf(t_1,d)+...+tf-idf(t_T,d)}}$$\n",
    "\n",
    "donde $T$ es el número total de términos.\n",
    "\n",
    "**Por ejemplo**, *si tenemos 3 términos en 3 resumenes, el primer término $t_1$ aparece 3 veces en el primer resumen $d_1$, 2 veces en el segundo resumen $d_2$ y 3 veces en el tercer resumen $d_3$. El segundo término $t_2$ aparece dos vez en el primer resumen $d_1$, y el tercer término $t_3$ solo aparece una vez en el tercer resumen $d_3$. *\n",
    "\n",
    "*Entonces $df(t_1)=3$, $df(t_2)=1$ y $df(t_3)=1$.*\n",
    "\n",
    "*Luego, $idf(t_1)=log(4/4)+1=1$, $idf(t_2)=idf(t_3)=1.69$.*\n",
    "\n",
    "*Por lo tanto, antes de normalizar, $tf-idf(t_1,d_1)=3\\times 1=3$, $tf-idf(t_2,d_1)=2\\times 1.69=3.38$ y $tf-idf(t_3,d_1)=0\\times 1.69=0$.* \n",
    "\n",
    "*Tras la normalización, tendriamos que  $tf-idf(d_1)=\\frac{(3,3.38,0)}{\\sqrt{9+11.42+0}}=(0.66,0.74,0)$*\n",
    "\n",
    "La biblioteca **scikit-learn** ofrece la clase *TfIdfVectorizer*, la cual produce una matriz TF-IDF de manera sencilla. Entonces, este índice lo calculamos utilizando los parámetros por defecto del transformador `TfidfTransformer`: `TfidfTransform(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)`.\n",
    "\n",
    "\n",
    "Como resultado, vamos a obtener una matriz cuyas columnas representan la relevancia (TF-IDF) de los términos presentes en los resumenes de cada película. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos el TfIdfVectorizer de la biblioteca scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el objeto TF-IDF. \n",
    "# También se podrían remover articulos (comunes) como 'the', 'a' con (stop_words='english')\n",
    "tfidf = TfidfVectorizer()  \n",
    "\n",
    "# Reemplazamos valores NaN con espacio vacío\n",
    "metadata['overview'] = metadata['overview'].fillna('')\n",
    "\n",
    "# Construimos la matriz TF-IDF ajustando y transfromando los datos\n",
    "tfidf_mat = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "# La salida con las dimensiones de tfidf_matrix\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3.1\n",
    "\n",
    "- Cuántos términos fueron necesarios para describir las peliculas de nuestra base de datos?\n",
    "\n",
    "- Qué tipo de matriz es `tfidf_mat`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos la primera pelicula y la representacion tfidf de su sinopsis\n",
    "print(metadata['overview'][0])\n",
    "print(tfidf_mat[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Cálculo de similitudes\n",
    "\n",
    "Ahora ya podemos calcular las similitudes entre las peliculas basados en sus resumenes. Podríamos utilizar distintas métricas, como la Euclideana, la correlación de Pearson, o la similitud del coseno. \n",
    "\n",
    "Por ejemplo, veamos qué ocurre con la similitud del coseno calculada para todo par de películas. Lo bueno de esta métrica del coseno es que es independiente de la magnitud y mide la dirección de los vectores. De este modo, dos vectores paralelos (con angulo relativo de 0°) tienen una similitud de 1, y dos vectores ortogonales, con un angulo de 90° entre ellos obtienen una similitud de 0.  \n",
    "\n",
    "La *similitud del coseno* se define para todo $x,y \\in [0,1]$ tal que\n",
    "\n",
    "$$\n",
    "sim_{cos}(x,y)=\\frac{\\sum_{i=1}^{n}x_i y_i}{\\sqrt{\\sum_{i=1}^{n}x_i^2} \\sqrt{\\sum_{i=1}^{n}y_i^2}}\n",
    "$$\n",
    "\n",
    "Como tenemos la matriz de representación vectorizada de las palabras para cada pelicula, el cómputo del producto interno obtiene de manera directa el valor de similitud por coseno. De esta manera, utilizamos el `linear_kernel()` de sklearn en lugar de `cosine_similarities()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos el linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cálculo de las similitudes para cada par de entre todas las 45466 peliculas y sus 76132 entradas es bastante pesado. Si ejecutamos el código sobre toda la matriz `tfidf_mat` en GoogleColab, debemos utilizar los recursos de RAM en la máquina remota. En nuestra máquina local tomemos un conjunto de peliculas más pequeño.\n",
    "\n",
    "Por ejemplo, tomemos solamente las peliculas más populares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metadata['vote_count'].quantile(0.90)\n",
    "pelis_P = metadata.copy().loc[metadata['vote_count'] >= m]\n",
    "pelis_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_P = tfidf_mat[ pelis_P.index, :]\n",
    "tfidf_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la matriz de similitudes por coseno (para un numero reducido de observaciones)\n",
    "sim_cos = linear_kernel(tfidf_P, tfidf_P)#], dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2\n",
    "\n",
    "Calcule las similitudes entre peliculas utilizando una funcion de similitud distinta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a definir una funcion que tome como entrada el título de una película y devuelve una lista de las peliculas más similares a esa película de entrada\n",
    "\n",
    "Para ello, primero tomamos una lista de referencia con los distintos titulos e indices de las peliculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(pelis_P.index, index=pelis_P['title']).drop_duplicates()\n",
    "indices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Funcion de recomendacion\n",
    "\n",
    "A continuación construimos la función de recomendación. Los pasos que se van a seguir son los siguientes:\n",
    "\n",
    "- Obtener el índice de la pelicula dado su título\n",
    "- Obtener la lista con los scores de similitud para esa película con respecto a las demás películas. \n",
    "- Ordenar la lista de tuplas en base al score de similitud\n",
    "- Obtener el top-k de peliculas más similares\n",
    "- Devolver los títulos que corresponden con los índices de las peliculas más similares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_pelis(titulo, num_pelis, sim):\n",
    "    # Indice de la pelicula para el titulo\n",
    "    idx = indices[titulo]\n",
    "\n",
    "    # Obtiene los valores de similtud para la pelicula de entrada\n",
    "    sim_scores = list(enumerate(sim[idx]))\n",
    "\n",
    "    # Ordena las peliculas a base a los scores de similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Scores de las k películas más similares (nótese que dejamos el primer elemento fuera)\n",
    "    sim_scores = sim_scores[1:num_pelis+1]\n",
    "\n",
    "    # Indices de las peliculas\n",
    "    pelis_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Devuelve las k peliculas mas similares\n",
    "    return pelis_P['title'].iloc[pelis_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_pelis('Toy Story', 7, sim_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque las primeras dos entradas de la recomendación parecen bastante acertadas, la tercera o la séptima recomendación parece totalmente inapropiada, sobre todo si tenemos en cuenta que la película de entrada está dirigida al público infantil. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos los géneros de nuestra base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generos = pelis_P.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "list(pd.unique(generos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3.3\n",
    "\n",
    "Qué solución puede plantear para este problema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.4\n",
    "\n",
    "Escriba su codigo a continuación, donde explore un mejor recomendador que el propuesto arriba. Note que no tenemos más información que la descripcion de las peliculas y su valoracion media. Por ello la evaluacion de la salida es, por el momento, completamente subjetiva (depende de usted). Explique por qué su propuesta es mejor que la que hemos desarrollado hasta el momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.5 \n",
    "\n",
    "Proponga una metodología, con su respectivo algoritmo, que permita medir, de acuerdo con una métrica de su elección, el nivel de acierto de las recomendaciones.\n",
    "\n",
    "*Ayuda: considere un sistema de recomendación basado en contenido donde solo hay un usuario (promedio)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
